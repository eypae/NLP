{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWhaphwAHmwV"
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. Reading in the Yelp reviews corpus\n",
    "2. Tokenizing the text\n",
    "3. Comparing the accuracy of different approaches\n",
    "4. Removing frequent terms (stop words)\n",
    "5. Removing infrequent terms\n",
    "6. Handling Unicode errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnWoSzHIHmwZ"
   },
   "source": [
    "## Part 1: Reading in the Yelp reviews corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyqHa1T3Hmwa"
   },
   "source": [
    "- \"corpus\" = collection of documents\n",
    "- \"corpora\" = plural form of corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HaAyz8cEHmwa",
    "outputId": "7083ea9c-1b5a-429c-dfa6-6112886d2a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# read yelp.csv into a DataFrame using a relative path\n",
    "import pandas as pd\n",
    "\n",
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "x6eDrSwnHmwc",
    "outputId": "f322689b-e44f-465c-bee0-3f25f6aa2e07"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date  ... useful  funny\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  ...      5      0\n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  ...      0      0\n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  ...      1      0\n",
       "\n",
       "[3 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/content/drive/My Drive/BT4222/data/yelp.csv'\n",
    "yelp = pd.read_csv(path)\n",
    "\n",
    "# examine the first three rows\n",
    "yelp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IumGUypPI8a0",
    "outputId": "b580b064-1a8b-4625-83ed-b5899505b777"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "id": "QQIjH6KaHmwg",
    "outputId": "ba666b36-3861-4c37-f67f-c09413bc0300"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\\n\\nDo yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I\\'ve ever had.  I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\\n\\nWhile EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I\\'ve ever had.\\n\\nAnyway, I can\\'t wait to go back!'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the text for the first row\n",
    "yelp.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbOwnCcuHmwi"
   },
   "source": [
    "**Goal:** Distinguish between 5-star and 1-star reviews using **only** the review text. (We will not be using the other columns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ionrtPiHmwi",
    "outputId": "67dbe9ce-9005-424d-9ad0-03c6845c049d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     749\n",
       "2     927\n",
       "3    1461\n",
       "4    3526\n",
       "5    3337\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "yelp.stars.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebdzdcC3Hmwl"
   },
   "outputs": [],
   "source": [
    "# create a new DataFrame that only contains the 5-star and 1-star reviews\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XWyHpq6VHmwm",
    "outputId": "31cbdd8f-0f04-42e5-edd6-79b48ecf7b58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the shape\n",
    "yelp_best_worst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0FbgJxzHmwo"
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = yelp_best_worst.text # yelp_best_worst['text']\n",
    "y = yelp_best_worst.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SECnzYSmHmwq"
   },
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vbKvRKxhHmwv",
    "outputId": "a7876a9f-658e-4d6a-f74f-3b8ebd175b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064,)\n",
      "(1022,)\n"
     ]
    }
   ],
   "source": [
    "# examine the object shapes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "id": "749NIqfmO6GB",
    "outputId": "cc4a3b12-58a2-4cc9-d420-d86a2eaa466c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\\n\\nDo yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I\\'ve ever had.  I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\\n\\nWhile EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I\\'ve ever had.\\n\\nAnyway, I can\\'t wait to go back!'"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb_6tQdRHmwx"
   },
   "source": [
    "## Part 2: Tokenizing the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnM6qzrMHmwy"
   },
   "source": [
    "- **What:** Separate text into units such as words, n-grams, or sentences\n",
    "- **Why:** Gives structure to previously unstructured text\n",
    "- **Notes:** Relatively easy with English language text, not easy with some languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7LVxf8cHmwy"
   },
   "outputs": [],
   "source": [
    "# use CountVectorizer to create document-term matrices from X_train and X_test\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfBSFxT4Hmw0"
   },
   "outputs": [],
   "source": [
    "# fit and transform X_train\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zausKpBUHmw3"
   },
   "outputs": [],
   "source": [
    "# only transform X_test\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23j1Ule-Hmw9",
    "outputId": "0956b5cb-0096-441f-ba01-bc6ce03822d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064, 16825)\n",
      "(1022, 16825)\n"
     ]
    }
   ],
   "source": [
    "# examine the shapes: rows are documents, columns are terms (aka \"tokens\" or \"features\")\n",
    "print(X_train_dtm.shape)\n",
    "print(X_test_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkNAUOJXHmxB",
    "outputId": "7291e57f-2500-4cf1-b76c-68a56fe49dc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yyyyy', 'z11', 'za', 'zabba', 'zach', 'zam', 'zanella', 'zankou', 'zappos', 'zatsiki', 'zen', 'zero', 'zest', 'zexperience', 'zha', 'zhou', 'zia', 'zihuatenejo', 'zilch', 'zin', 'zinburger', 'zinburgergeist', 'zinc', 'zinfandel', 'zing', 'zip', 'zipcar', 'zipper', 'zippers', 'zipps', 'ziti', 'zoe', 'zombi', 'zombies', 'zone', 'zones', 'zoning', 'zoo', 'zoyo', 'zucca', 'zucchini', 'zuchinni', 'zumba', 'zupa', 'zuzu', 'zwiebel', 'zzed', 'éclairs', 'école', 'ém']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 features\n",
    "print(vect.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dh4F92n0HmxD",
    "outputId": "02dee7ac-9941-473e-8803-b1995bca2faa",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show default parameters for CountVectorizer\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_GSLmKNHmxF"
   },
   "source": [
    "[CountVectorizer documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hfib-s94HmxF"
   },
   "source": [
    "- **lowercase:** boolean, True by default\n",
    "    - Convert all characters to lowercase before tokenizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojUEZ5G4HmxG",
    "outputId": "e5b00caf-1898-413a-88eb-a44032d06ce9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 20838)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't convert to lowercase\n",
    "vect = CountVectorizer(lowercase=False)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q74lpfLpHmxI"
   },
   "source": [
    "- **ngram_range:** tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "    - All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxO_IBoOHmxI",
    "outputId": "12a70cd4-00bd-4a49-95e9-cf5eda16d999"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 169847)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMA2qVBxHmxK",
    "outputId": "87fd8a5e-e96e-4af6-a59f-b8f5769a39b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zone out', 'zone when', 'zones', 'zones dolls', 'zoning', 'zoning issues', 'zoo', 'zoo and', 'zoo is', 'zoo not', 'zoo the', 'zoo ve', 'zoyo', 'zoyo for', 'zucca', 'zucca appetizer', 'zucchini', 'zucchini and', 'zucchini bread', 'zucchini broccoli', 'zucchini carrots', 'zucchini fries', 'zucchini pieces', 'zucchini strips', 'zucchini veal', 'zucchini very', 'zucchini with', 'zuchinni', 'zuchinni again', 'zuchinni the', 'zumba', 'zumba class', 'zumba or', 'zumba yogalates', 'zupa', 'zupa flavors', 'zuzu', 'zuzu in', 'zuzu is', 'zuzu the', 'zwiebel', 'zwiebel kräuter', 'zzed', 'zzed in', 'éclairs', 'éclairs napoleons', 'école', 'école lenôtre', 'ém', 'ém all']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 features\n",
    "print(vect.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQa2qGOCHmxM"
   },
   "source": [
    "## Part 3: Comparing the accuracy of different approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5POwz5LKHmxN"
   },
   "source": [
    "**Approach 1:** Always predict the most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9IjRVKMPX05",
    "outputId": "30adb682-4494-4288-dbe8-1489234bff37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    838\n",
       "1    184\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SX5cXg0CPjM1",
    "outputId": "959c5214-3383-4003-cde5-62e991c9cd44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022,)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gShesEuvHmxN",
    "outputId": "d2738e28-f041-4973-eae2-ecf77ba4919e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.819961\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy\n",
    "y_test.value_counts().head(1) / y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXxdCLHPHmxQ",
    "outputId": "7f961144-2e20-49f3-a0a7-e61427b006de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8199608610567515"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "\n",
    "dummy.fit(X_train_dtm, y_train)\n",
    "\n",
    "y_pred_class = dummy.predict(X_test_dtm)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaszEP2VHmxR"
   },
   "source": [
    "**Approach 2:** Use the default parameters for CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vPq2AsOHmxR"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# define a function that accepts a vectorizer and calculates the accuracy\n",
    "def tokenize_test(X_train, y_train, X_test, y_test, vect):\n",
    "    # create document-term matrices using the vectorizer\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    \n",
    "    # print the number of features that were generated\n",
    "    print('Features: ', X_train_dtm.shape[1])\n",
    "    \n",
    "    # use Multinomial Naive Bayes to predict the star rating\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "    \n",
    "    # Get the training accuracy\n",
    "    print('Training Accuracy: ', metrics.accuracy_score(y_train, nb.predict(X_train_dtm)))\n",
    "    # print the accuracy of its predictions\n",
    "    print('Test Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RX4ThyyJHmxT",
    "outputId": "dfa876e7-8dee-4e2d-f982-f101c96ee222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  16825\n",
      "Training Accuracy:  0.972911227154047\n",
      "Test Accuracy:  0.9187866927592955\n"
     ]
    }
   ],
   "source": [
    "# use the default parameters\n",
    "vect = CountVectorizer()\n",
    "tokenize_test(X_train, y_train, X_test, y_test, vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEVFQxuSHmxV"
   },
   "source": [
    "**Approach 3:** Don't convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNu5vNJOHmxW",
    "outputId": "402f3dd5-adfb-4f82-ceeb-629c67ba930b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  20838\n",
      "Training Accuracy:  0.9768276762402088\n",
      "Test Accuracy:  0.9099804305283757\n"
     ]
    }
   ],
   "source": [
    "# don't convert to lowercase\n",
    "vect = CountVectorizer(lowercase=False)\n",
    "tokenize_test(X_train, y_train, X_test, y_test, vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzWqRWA7Hmxa"
   },
   "source": [
    "**Approach 4:** Include 1-grams and 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NgY3XPfHmxa",
    "outputId": "d779ebdb-243e-44a6-cdaa-dd98c6e86170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  169847\n",
      "Training Accuracy:  0.993798955613577\n",
      "Test Accuracy:  0.8542074363992173\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "tokenize_test(X_train, y_train, X_test, y_test, vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dJZux7kHmxh"
   },
   "source": [
    "**Summary:** Tuning CountVectorizer is a form of **feature engineering**, the process through which you create features that don't natively exist in the dataset. Your goal is to create features that contain the **signal** from the data (with respect to the response value), rather than the **noise**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCpKzA6FHmxi"
   },
   "source": [
    "## Part 4: Removing frequent terms (stop words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asSiVImhHmxi"
   },
   "source": [
    "- **What:** Remove common words that appear in most documents\n",
    "- **Why:** They probably don't tell you much about your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "279wHB7LHmxj",
    "outputId": "a3e54ce0-93ce-4508-8145-a27129bbf864"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show vectorizer parameters\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFdzbprKHmxk"
   },
   "source": [
    "- **stop_words:** string {'english'}, list, or None (default)\n",
    "    - If 'english', a built-in stop word list for English is used.\n",
    "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "    - If None, no stop words will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6TYyLOiHmxl",
    "outputId": "56742ebd-c0a0-421f-f934-0b892a912e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  16528\n",
      "Training Accuracy:  0.9758485639686684\n",
      "Test Accuracy:  0.9158512720156555\n"
     ]
    }
   ],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "tokenize_test(X_train, y_train, X_test, y_test, vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoOOls8KDA1y"
   },
   "outputs": [],
   "source": [
    "Features:  16825\n",
    "Training Accuracy:  0.972911227154047\n",
    "Test Accuracy:  0.9187866927592955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78wDdaH4Hmxn",
    "outputId": "9b53b3c1-4f91-454f-e1fe-816c291f9d8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'con', 'could', 'couldnt', 'cry', 'de', 'describe', 'detail', 'do', 'done', 'down', 'due', 'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed', 'interest', 'into', 'is', 'it', 'its', 'itself', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'rather', 're', 'same', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system', 'take', 'ten', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'until', 'up', 'upon', 'us', 'very', 'via', 'was', 'we', 'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "# examine the stop words\n",
    "print(sorted(vect.get_stop_words()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKadJwKfHmxp"
   },
   "source": [
    "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TLGTbFJFHmxq",
    "outputId": "eb038e30-dd5e-4380-89af-10d5a939e4d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  16815\n",
      "Training Accuracy:  0.9751958224543081\n",
      "Test Accuracy:  0.9207436399217221\n"
     ]
    }
   ],
   "source": [
    "# ignore terms that appear in more than 50% of the documents\n",
    "vect = CountVectorizer(max_df=0.5)\n",
    "tokenize_test(X_train, y_train, X_test, y_test, vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrkTyizVHmxt"
   },
   "source": [
    "- **stop\\_words\\_:** Terms that were ignored because they either:\n",
    "    - occurred in too many documents (max_df)\n",
    "    - occurred in too few documents (min_df)\n",
    "    - were cut off by feature selection (max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYqpr4l3Hmxu",
    "outputId": "248c6afb-b194-41e9-a7cb-e8ce5ad0f1ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'of', 'to', 'the', 'in', 'and', 'it', 'my', 'this', 'is', 'for'}\n"
     ]
    }
   ],
   "source": [
    "# examine the terms that were removed due to max_df (\"corpus-specific stop words\")\n",
    "print(vect.stop_words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLso7fZIHmxw",
    "outputId": "5a1fa0cc-80b2-40eb-a3d4-41a362f7013e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# vect.stop_words_ is completely distinct from vect.get_stop_words()\n",
    "print(vect.get_stop_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRBy5ecoHmxz"
   },
   "source": [
    "## Part 5: Removing infrequent terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAMvRwXoHmxz"
   },
   "source": [
    "- **max_features:** int or None, default=None\n",
    "    - If not None, build a vocabulary that only considers the top max_features ordered by term frequency across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTHCL0X2Hmxz",
    "outputId": "c1532499-23d0-42e3-9e16-0bc1bd31e093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  1000\n",
      "Training Accuracy:  0.9275456919060052\n",
      "Test Accuracy:  0.8923679060665362\n"
     ]
    }
   ],
   "source": [
    "# only keep the top 1000 most frequent terms\n",
    "vect = CountVectorizer(max_features=1000)\n",
    "tokenize_test(X_train, y_train, X_test, y_test, vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjg6TzVwHmx1"
   },
   "source": [
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8L6ArKYHmx2",
    "outputId": "0928f578-59f6-4852-b994-cb5c0ab41eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  8783\n",
      "Training Accuracy:  0.966710182767624\n",
      "Test Accuracy:  0.9246575342465754\n"
     ]
    }
   ],
   "source": [
    "# only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(min_df=2)\n",
    "tokenize_test(X_train, y_train, X_test, y_test, vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-K4Qb7tGHmx4",
    "outputId": "46a91e49-4571-4556-988c-b2bedd6011a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  43957\n",
      "Training Accuracy:  0.9895561357702349\n",
      "Test Accuracy:  0.9324853228962818\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams, and only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tokenize_test(X_train, y_train, X_test, y_test, vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wdzby-0yHmx7"
   },
   "source": [
    "**Guidelines for tuning CountVectorizer:**\n",
    "\n",
    "- Use your knowledge of the **problem** and the **text**, and your understanding of the **tuning parameters**, to help you decide what parameters to tune and how to tune them.\n",
    "- **Experiment**, and let the data tell you the best approach!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Om4WP13qHmx7"
   },
   "source": [
    "## Part 6: Handling Unicode errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8eJKo3xHmx8"
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#decoding-text-files):\n",
    "\n",
    "> Text is made of **characters**, but files are made of **bytes**. These bytes represent characters according to some **encoding**. To work with text files in Python, their bytes must be decoded to a character set called **Unicode**. Common encodings are ASCII, Latin-1 (Western Europe), KOI8-R (Russian) and the universal encodings UTF-8 and UTF-16. Many others exist.\n",
    "\n",
    "**Why should you care?**\n",
    "\n",
    "When working with text in Python, you are likely to encounter errors related to encoding, and understanding Unicode will help you to troubleshoot these errors.\n",
    "\n",
    "**Unicode basics:**\n",
    "\n",
    "- Unicode is a system that assigns a unique number for every character in every language. These numbers are called **code points**. For example, the [code point](http://www.unicode.org/charts/index.html) for \"A\" is U+0041, and the official name is \"LATIN CAPITAL LETTER A\".\n",
    "- An **encoding** specifies how to store the code points in memory:\n",
    "    - **UTF-8** is the most popular Unicode encoding. It uses 8 to 32 bits to store each character.\n",
    "    - **UTF-16** is the second most popular Unicode encoding. It uses 16 or 32 bits to store each character.\n",
    "    - **UTF-32** is the least popular Unicode encoding. It uses 32 bits to store each character.\n",
    "\n",
    "**ASCII basics:**\n",
    "- ASCII is an encoding from the 1960's that uses 8 bits to store each character, and only supports **English characters**.\n",
    "- ASCII-encoded files are sometimes called **plain text**.\n",
    "- UTF-8 is **backward-compatible** with ASCII, because the first 8 bits of a UTF-8 encoding are identical to the ASCII encoding.\n",
    "\n",
    "The default encoding in **Python 2** is ASCII. The default encoding in **Python 3** is UTF-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFlNOSwQHmyC",
    "outputId": "c5e68f2e-c6a2-4d7a-ae6c-3d1478191fb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Python 3: examine two types of strings\n",
    "print(type(b'hello'))\n",
    "print(type('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drNMx8M0HmyE",
    "outputId": "3512b056-5ec5-4643-e000-08ded3ac2b55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python 3: 'decode' converts 'bytes' to 'str'\n",
    "b'hello'.decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1ocza_mHmyG",
    "outputId": "0b3c3b44-8ab1-460f-bfe4-e917add2bd9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python 3: 'encode' converts 'str' to 'bytes'\n",
    "'hello'.encode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uiq9tU-I9d5T",
    "outputId": "6668b494-bca3-4545-ca10-420f4946b27e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xce\\xb1\\xce\\xac'\n",
      "<class 'bytes'>\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Python 3: 'encode' converts 'str' to 'bytes'\n",
    "a = \"αά\".encode('utf-8')\n",
    "print (a)\n",
    "print (type(a))\n",
    "print (len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t5iZKfGV902-",
    "outputId": "daaa8767-c45b-47bb-e261-dfdb2fe305ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'αά'"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90z7H-1a98t0",
    "outputId": "09913253-0b03-4684-ee8e-05d6153f3d96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'α'"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b'\\xce\\xb1'.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ4_DNg3HmyH"
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#decoding-text-files):\n",
    "\n",
    "> The text feature extractors in scikit-learn know how to **decode text files**, but only if you tell them what encoding the files are in. The CountVectorizer takes an **encoding parameter** for this purpose. For modern text files, the correct encoding is probably **UTF-8**, which is therefore the default (encoding=\"utf-8\").\n",
    "\n",
    "> If the text you are loading is not actually encoded with UTF-8, however, you will get a **UnicodeDecodeError**. The vectorizers can be told to be silent about decoding errors by setting the **decode_error parameter** to either \"ignore\" or \"replace\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjdqk2n-W7jR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "04 Natural Language Processing using NB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
